#!/usr/bin/php -q
<?php

// Dataset class

class HedgehogDataset
{
	private $global_settings;
	private $dataset;
	private $creation_time;
	private $triples_file;
	private $import_file_format;
	private $hopper_path;
	private $dumps_path;
	private $remote_path;
	private $triples_count;
	private $config;
	private $dumpfiles;
	
	public $quiet;
	public $force;
	public $errors;
	public $status;

	function createSettings($settings_path)
	{
		$r = array();
		if(is_dir($settings_path))
		{
			if ($handle = opendir($settings_path))
			{
				while (false !== ($entry = readdir($handle)))
				{
					$full_path = $settings_path . "/" . $entry;
					if(!(is_dir($full_path)))
					{
						$lines = file($full_path);
						foreach($lines as $line)
						{
							$settingline = trim($line);
							if(strlen($settingline) > 0)
							{
								if(strcmp(substr($settingline, 0, 1), "#") != 0)
								{
									$settingarray = explode(" ", $settingline, 2);
									if(count($settingarray) == 2)
									{
										$k = $settingarray[0];
										$r[$k] = $settingarray[1];
									}
								}
							}
						}
					}
				}
				closedir($handle);
			}		
		}
		$this->global_settings = $r;
	}

	// Function to check all files and data are present and correct
	private function checkSettings()
	{
		$global_settings = $this->global_settings;
		$dataset = $this->dataset;
		$result = "";
		
		// Check to see all the relevant directories exist
		
		$errors = array();
		if(!(is_dir($global_settings['hashes_dir'])))
		{
			$errors[] = $global_settings['hashes_dir'];
		}
		if(!(is_dir($global_settings['dumps_dir'])))
		{
			$errors[] = $global_settings['dumps_dir'];
		}
		if(!(is_dir($global_settings['quills_dir'])))
		{
			$errors[] = $global_settings['quills_dir'];
		}
		if(!(is_dir($global_settings['tools_dir'])))
		{
			$errors[] = $global_settings['tools_dir'];
		}
		if(!(is_dir($global_settings['tmp_dir'])))
		{
			$errors[] = $global_settings['tmp_dir'];
		}
		if(count($errors) > 0)
		{
			$result .= "The following directories cannot be found: \n- " . implode("\n- ", $errors) . "\n\n";
			return($result);
		}
		
		// Check to see if the dataset directory exists
		$errors = array();
		$dataset_path = $global_settings['quills_dir'] . "/" . $dataset;
		$dataset_cfg = $dataset_path . "/publish.json";
		if(!(file_exists($dataset_cfg)))
		{
			$errors[] = $dataset . " - publish.json does not exist";
		}
		if(count($errors) > 0)
		{
			$result .= "The following datasets cannot be imported:\n  * " . implode("\n  * ", $errors) . "\n";
			$result .= "Configuration files do not appear to exist.\n\n";
			return($result);
		}
		
		// Check to see if the config file is valid
		$errors = array();
		$dataset_path = $global_settings['quills_dir'] . "/" . $dataset;
		$dataset_cfg = $dataset_path . "/publish.json";
		@$json_obj = json_decode(implode("", file($dataset_cfg)), true);
		if(!(is_array($json_obj))) {
			$json_obj = array();
		}
		if( json_last_error() == JSON_ERROR_DEPTH )
		{
			$errors[] =  $dataset.' - Maximum stack depth exceeded in JSON';
		}
		if( json_last_error() == JSON_ERROR_CTRL_CHAR )
		{
			$errors []= $dataset.' - Unexpected control character found in JSON';
		}
		if( json_last_error() == JSON_ERROR_SYNTAX )
		{
			$errors []= $dataset.' - Syntax error, malformed JSON';
		}
		if( !count( $errors ))
		{
			# only look for errors inside the JSON if the JSON was parsed OK
			if(!(array_key_exists("properties", $json_obj)))
			{
				$errors[] = $dataset. " - missing 'properties' section in publish.json";
			}
			if((!(array_key_exists("additional_triples", $json_obj))) & (!(array_key_exists("triples", $json_obj))))
			{
				$errors[] = $dataset. " - missing 'additional_triples' AND 'triples' sections in publish.json";
			}
			if(!(array_key_exists("downloads", $json_obj)))
			{
				$errors[] = $dataset. " - missing 'downloads' section in publish.json";
			}
			if(!(array_key_exists("tools", $json_obj)))
			{
				$errors[] = $dataset. " - missing 'tools' section in publish.json";
			}
			if(!(array_key_exists("files", $json_obj)))
			{
				$errors[] = $dataset. " - missing 'files' section in publish.json";
			}
			if(!(array_key_exists("commands", $json_obj)))
			{
				$errors[] = $dataset. " - missing 'commands' section in publish.json";
			}
		}
		if(count($errors) > 0)
		{
			$result .= "The following datasets cannot be imported:\n  * " . implode("\n  * ", $errors) . "\n";
			$result .= "The configuration files appear to be invalid.\n\n";
			return($result);
		}
		
		// Check that all the necessary files exist
		$errors = array();
		$dataset_path = $global_settings['quills_dir'] . "/" . $dataset;
		$dataset_cfg = $dataset_path . "/publish.json";
		@$json_obj = json_decode(implode("", file($dataset_cfg)), true);
		$files_list = $json_obj['files'];
		@chdir($dataset_path);
		foreach($files_list as $file_req)
		{
			if(!(file_exists($file_req)))
			{
				$errors[] = $dataset;
			}
		}
		if(count($errors) > 0)
		{
			$result .= "The following datasets cannot be imported: " . implode(", ", $errors) . ".\n";
			$result .= "Files defined in the configuration file are not present.\n\n";
			return($result);
		}
		
		// Check that the dataset actually has an import instruction
		$errors = array();
		$dataset_path = $global_settings['quills_dir'] . "/" . $dataset;
		$dataset_cfg = $dataset_path . "/publish.json";
		@$json_obj = json_decode(implode("", file($dataset_cfg)), true);
		$properties_list = $json_obj['properties'];
		if(!(array_key_exists("import_file", $properties_list)))
		{
			$errors[] = $dataset;
		}
		if(count($errors) > 0)
		{
			$result .= "The following datasets cannot be imported: " . implode(", ", $errors) . ".\n";
			$result .= "No import command can be found.\n\n";
			return($result);
		}

		return($result);
	}

	public function prepare()
	{
		// Process command line switches
		$quiet = $this->quiet;
		$force_import = $this->force;

		// Set up local variables
		$dataset = $this->dataset;
		@$quills_dir = $this->global_settings['quills_dir'];
		@$target_base_url = $this->global_settings['target_base_url'];
		@$tmp_dir = $this->global_settings['tmp_dir'];
		@$rapper_path = $this->global_settings['rapper_path'];
		@$tools_dir = $this->global_settings['tools_dir'];
		@$hashes_dir = $this->global_settings['hashes_dir'];

		// Create directories for processing
		$date = date("Y-m-d");
		$source_dir = $quills_dir . "/" . $dataset;
		$target_dir = $this->hopper_path;
		$dataset_cfg = $source_dir . "/publish.json";
		$ntriples_file = $this->triples_file;
		
		// Ensure dump directory exists (if specified)
		$dumps_dir = "";
		@$dumps_dir = $this->global_settings['dumps_dir'];
		$datestring = date("Y-m-d");
		if(is_dir($dumps_dir))
		{
			$dumps_dir = $dumps_dir . "/" . $dataset;
			if(!(is_dir($dumps_dir)))
			{
				mkdir($dumps_dir);
			}
			$dumps_dir = $dumps_dir . "/" . $datestring;
			if(is_dir($dumps_dir))
			{
				deltree($dumps_dir);
			}
			mkdir($dumps_dir, 0755, true);
			$this->dumps_path = $dumps_dir;
		}
		$this->remote_path = $this->global_settings['target_base_url'] . "/" . $dataset . "/" . $datestring;

		// Read the configuration file
		$cfg_obj = json_decode(implode("", file($dataset_cfg)), true);
		$cfg_properties = $cfg_obj['properties'];
		if(array_key_exists("additional_triples", $cfg_obj))
		{
			$cfg_triples = $cfg_obj['additional_triples'];
		} else {
			$cfg_triples = $cfg_obj['triples'];
		}
		$cfg_downloads = $cfg_obj['downloads'];
		$cfg_files = $cfg_obj['files'];
		$cfg_tools = $cfg_obj['tools'];
		$cfg_commands = $cfg_obj['commands'];
		$cfg_commands_prepare = $cfg_commands['prepare'];
		$cfg_commands_import = $cfg_commands['import'];
		$cfg_import = $cfg_properties['import_file'];
		$cfg_force = (!($cfg_properties['check_hashes']));
		$this->config = $cfg_obj;
		
		$force_import = ($force_import | $cfg_force);
		$this->force = $force_import;
		
		// Show the current dataset, for debugging purposes.
		if(!$quiet)
		{
			print(" - " . $dataset . "\n");
		}
		
		// Copy contents of quill directory into hopper
		if(is_dir($source_dir))
		{
			dupdir($source_dir, $target_dir);
		}
		
		// Begin the downloading
		chdir($target_dir);
		$download_start_time = date("c");
		foreach($cfg_downloads as $download)
		{
			$file_local = $download['localfile'];
			$file_remote = $download['download'];
			if(!$quiet)
			{
				print("     Downloading " . $file_local . "\n");
			}
			wget($file_remote, $file_local);
		}
		$download_end_time = date("c");
	
		// Install the required tools
		chdir($target_dir);
		foreach($cfg_tools as $tool)
		{
			if(!$quiet)
			{
				print("     Installing " . $tool . "\n");
			}
			$file_perms = fileperms($tools_dir . "/" . $tool);
			copy($tools_dir . "/" . $tool, "./" . $tool);
			chmod("./" . $tool, $file_perms);
		}
		
		// Run preparation script(s)
		chdir($target_dir);
		foreach($cfg_commands_prepare as $command)
		{
			if(!$quiet)
			{
				print("       " . $command . "\n");
			}
			//shell_exec($command . " 2>&1");
			shell_exec($command);
		}
	}
	
	// The following two functions handle hash checks. The hashCheck function isn't public because it has side effects, so
	// it may return different results if called twice during the same process, which we don't really want. The changedFiles
	// function remedies this by caching the value returned by hashCheck so it's only called once.
	
	public function changedFiles()
	{
		if(!(array_key_exists("hash_check", $this->global_settings)))
		{
			$this->global_settings['hash_check'] = $this->hashCheck();
		}
		return($this->global_settings['hash_check']);
	}
	
	private function hashCheck()
	{
		$hashes_dir = "";
		@$hashes_dir = $this->global_settings['hashes_dir'];
		if(!(is_dir($hashes_dir)))
		{
			$ret_val = true; // If the hash directory is not defined or nonexistant, we say files have changed, to force a publish.
		}
		else
		{
			$hash_file = $hashes_dir . "/" . $this->dataset . ".hashes";
			$quiet = $this->quiet;
			if(!$quiet)
			{
				print("     Checking hashes\n");
			}
			// Load previous hashes
			$old_hashes = array();
			$ret_val = false;
			if(file_exists($hash_file))
			{
				$f = file($hash_file);
				foreach($f as $l)
				{
					if(strlen($l) > 0)
					{
						$a = explode(" ", $l, 2);
						$k = trim($a[1]);
						$v = trim($a[0]);
						$old_hashes[$k] = $v;
					}
				}
			} else {
				$ret_val = true;
			}
			if ($handle = opendir("."))
			{
				$fp = fopen($hash_file, "w");
				while (false !== ($entry = readdir($handle)))
				{
					if(!(is_dir($entry)))
					{
						$new_hash = md5_file("./" . $entry);
						fwrite($fp, $new_hash . " " . $entry . "\n");
						if(!(array_key_exists($entry, $old_hashes)))
						{
							$ret_val = true;
							//print("       " . $entry . " added\n");
						} else {
							if(strcmp($new_hash, $old_hashes[$entry]) != 0)
							{
								$ret_val = true;
								//print("       " . $entry . " changed\n");
							}
						}
					}
				}
				fclose($fp);
			}
		}
		return($ret_val);
	}
	
	public function requestRdfDump($filename, $format)
	{
		$item = array();
		$item['filename'] = $filename;
		$item['format'] = $format;
		$this->dumpfiles[] = $item;
	}
	
	public function publish()
	{

		// Process command line switches
		$quiet = $this->quiet;
		$force_import = $this->force;

		// Set up local variables
		$dataset = $this->dataset;
		@$target_base_url = $this->global_settings['target_base_url'];
		@$rapper_path = $this->global_settings['rapper_path'];
		$triples_count = 0;
		
		// Create directories for processing
		$hopper_dir = $this->hopper_path;
		$dumps_dir = $this->dumps_path;
		$ntriples_file = $this->triples_file;
		
		// Read the configuration file
		$cfg_obj = $this->config;
		$cfg_properties = $cfg_obj['properties'];
		if(array_key_exists("additional_triples", $cfg_obj))
		{
			$cfg_triples = $cfg_obj['additional_triples'];
		} else {
			$cfg_triples = $cfg_obj['triples'];
		}
		$cfg_downloads = $cfg_obj['downloads'];
		$cfg_files = $cfg_obj['files'];
		$cfg_tools = $cfg_obj['tools'];
		$cfg_commands = $cfg_obj['commands'];
		$cfg_commands_prepare = $cfg_commands['prepare'];
		$cfg_commands_import = $cfg_commands['import'];
		$cfg_import = $cfg_properties['import_file'];

		// Generate import data if necessary.
		chdir($hopper_dir);
		foreach($cfg_commands_import as $command)
		{
			if(!$quiet)
			{
				print("       " . $command . "\n");
			}
			shell_exec($command);
		}
		
		// Final check before importing - does the import file exist?
		if(!(file_exists($cfg_import)))
		{
			if(!$quiet)
			{
				print("     IMPORT FAILED ## Could not find specified import file '" . $cfg_import . "'\n");
			}
		}
		else
		{
			// Import the triples to an array for passing back to the main script

			if(!$quiet)
			{
				print("     Generating triples\n");
			}
			if(file_exists($rapper_path))
			{
				$cmd_line = $rapper_path . " -g -o ntriples " . $cfg_import . " > " . $ntriples_file;
				if(!$quiet)
				{
					print("       " . $cmd_line . "\n");
				}
				$ret_val = externalScript($cmd_line);
				if(!$quiet)
				{
					if(strlen($ret_val['stderr']) > 0)
					{
						print("         " . trim(str_replace("\n", "\n         ", $ret_val['stderr'])) . "\n");
					}
				}
				// Get the number of triples - bit hacky but does the job until I can think of something better.
				// We could count the lines in the ntriples file, but that would take far too much time with massive datasets.
				$m = array();
				if(preg_match("/returned ([0-9]+) triples/", $ret_val['stderr'], $m) > 0)
				{
					$triples_count = (int) $m[1];
				}
				// Now use the same method to get the name of the parser used.
				$m = array();
				if(preg_match("/parser name \'([a-zA-Z0-9]+)\'/", $ret_val['stderr'], $m) > 0)
				{
					$ntriples_file_format = strtolower($m[1]);
				}
			} else {
				// TODO: Alternative Graphite-based import
			}
		}
		$this->import_file_format = $ntriples_file_format;

		// We have everything we need to import, so we can go about preparing the raw data files for publishing
		// Start by deleting anthing with .private as an extension.
		if(!$quiet)
		{
			print("     Deleting .private files\n");
		}			
		$files = glob('./*.private');
		foreach($files as $file){
			if(is_file($file))
			{
					unlink($file); // delete file
			}
		}

		// Add some provenance triples
		if(!$quiet)
		{
			print("     Adding provenance triples\n");
		}			
		$triples = $this->getProvenanceTriples();
		$triples_count = $triples_count + count($triples);
		$this->triples_count = $triples_count;
		$fp = fopen($ntriples_file, "a");
		fwrite($fp, implode("\n", $triples) . "\n");
		fclose($fp);
		
		// Produce dumps
		if(file_exists($rapper_path))
		{
			foreach($this->dumpfiles as $dumpfile)
			{
				$localfile = $dumpfile['filename'];
				$format = $dumpfile['format'];
				$remotefile = $this->remote_path . "/" . $localfile;
				if(!$quiet)
				{
					print("     Creating dump file " . $localfile . "\n");
					//print("     " . $remotefile . "\n");
				}
				$filename_parse = explode("/", trim($cfg_import, "/"));
				$cfg_import_localname = $filename_parse[(count($filename_parse) - 1)];
				$cmd_line = $rapper_path . " -i ntriples -o " . $format . " " . $ntriples_file . " | sed s#\\<file\\:[^\\>]*" . $cfg_import_localname . "\\>#\\<\\># | sed s#\\<" . $remotefile . "\\>#\\<\\># > " . $hopper_dir . "/" . $localfile ;
				$ret_val = externalScript($cmd_line);
			}
		} else {
			// TODO: Alternative Graphite-based export
		}
		
		// Copy the hopper to the dumps file
		dupdir($hopper_dir, $dumps_dir);
		
	}
	
	private function getProvenanceTriples()
	{
		$cfg_obj = $this->config;
		$cfg_downloads = $cfg_obj['downloads'];
		$cfg_files = $cfg_obj['files'];
		$cfg_properties = $cfg_obj['properties'];
		$cfg_import = $cfg_properties['import_file'];
		$cfg_dumpfiles = $this->dumpfiles;
		$remote_path = $this->remote_path;

		$triples = array();
		$datestring = date("c", $this->creation_time);
		$datenow = date("c");
		$localfile_arr = explode("/", $cfg_import);
		$localfile = $localfile_arr[(count($localfile_arr) - 1)];
		$base_uri = $remote_path . "/" . $localfile . "#provenance";
		$triples[] = "<" . $base_uri . "> <http://purl.org/void/provenance/ns/processType> <http://id.southampton.ac.uk/ns/ConvertAndPublishDataset> .";
		$triples[] = "<" . $base_uri . "> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://purl.org/void/provenance/ns/ProvenanceEvent> .";
		$triples[] = "<" . $base_uri . "> <http://www.w3.org/2006/time#hasBeginning> \"" . $datestring . "\"^^<http://www.w3.org/2001/XMLSchema#dateTime> .";
		$triples[] = "<" . $base_uri . "> <http://www.w3.org/2006/time#hasEnd> \"" . $datenow . "\"^^<http://www.w3.org/2001/XMLSchema#dateTime> .";
		$triples[] = "<" . $base_uri . "> <http://purl.org/void/provenance/ns/resultingDataset> <" . str_replace("#provenance", "", $base_uri) . "> .";
		foreach($cfg_downloads as $download)
		{
			$localfile_arr = explode("/", $download['localfile']);
			$localfile = $localfile_arr[(count($localfile_arr) - 1)];
			$uri = $remote_path . "/" . $localfile . "#provenance";
			$triples[] = "<" . $uri . "> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://purl.org/void/provenance/ns/ProvenanceEvent> .";
			$triples[] = "<" . $uri . "> <http://purl.org/void/provenance/ns/processType> <http://id.southampton.ac.uk/ns/DownloadViaHTTP> .";
			$triples[] = "<" . $uri . "> <http://purl.org/void/provenance/ns/resultingDataset> <" . $remote_path . "/" . $localfile . "> .";
			$triples[] = "<" . $uri . "> <http://purl.org/void/provenance/ns/sourceDataset> <" . $download['download'] . "> .";
			$triples[] = "<" . $uri . "> <http://www.w3.org/2006/time#hasBeginning> \"" . $datestring . "\"^^<http://www.w3.org/2001/XMLSchema#dateTime> .";
			$triples[] = "<" . $uri . "> <http://www.w3.org/2006/time#hasEnd> \"" . $datenow . "\"^^<http://www.w3.org/2001/XMLSchema#dateTime> .";
			$triples[] = "<" . $base_uri . "> <http://purl.org/void/provenance/ns/sourceDataset> <" . $remote_path . "/" . $localfile . "> .";
		}
		foreach($cfg_files as $file)
		{
			$localfile_arr = explode("/", $file);
			$localfile = $localfile_arr[(count($localfile_arr) - 1)];
			$triples[] = "<" . $base_uri . "> <http://id.southampton.ac.uk/ns/processIncludedFile> <" . $remote_path . "/" . $localfile . "> .";
		}
		foreach($this->dumpfiles as $dumpfile)
		{
			$localfile = $dumpfile['filename'];
			$format = $dumpfile['format'];
			$uri = $remote_path . "/" . $localfile . "#provenance";
			if(strcmp($base_uri, $remote_path . "/" . $localfile . "#provenance") != 0)
			{
				$triples[] = "<" . $uri . "> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://purl.org/void/provenance/ns/ProvenanceEvent> .";
				if(strcmp($this->import_file_format, "turtle") == 0)
				{
					if(strcmp($format, "rdfxml") == 0)
					{
						$triples[] = "<" . $uri . "> <http://purl.org/void/provenance/ns/processType> <http://id.southampton.ac.uk/ns/ConvertTurtleToRDFXML> .";
					}
					elseif(strcmp($format, "ntriples") == 0)
					{
						$triples[] = "<" . $uri . "> <http://purl.org/void/provenance/ns/processType> <http://id.southampton.ac.uk/ns/ConvertTurtleToNTriples> .";
					}
				}
				elseif(strcmp($this->import_file_format, "rdfxml") == 0)
				{
					if(strcmp($format, "turtle") == 0)
					{
						$triples[] = "<" . $uri . "> <http://purl.org/void/provenance/ns/processType> <http://id.southampton.ac.uk/ns/ConvertRDFXMLToTurtle> .";
					}
					elseif(strcmp($format, "ntriples") == 0)
					{
						$triples[] = "<" . $uri . "> <http://purl.org/void/provenance/ns/processType> <http://id.southampton.ac.uk/ns/ConvertRDFXMLToNTriples> .";
					}
				}
				elseif(strcmp($this->import_file_format, "ntriples") == 0)
				{
					if(strcmp($format, "rdfxml") == 0)
					{
						$triples[] = "<" . $uri . "> <http://purl.org/void/provenance/ns/processType> <http://id.southampton.ac.uk/ns/ConvertNTriplesToRDFXML> .";
					}
					elseif(strcmp($format, "turtle") == 0)
					{
						$triples[] = "<" . $uri . "> <http://purl.org/void/provenance/ns/processType> <http://id.southampton.ac.uk/ns/ConvertNTriplesToTurtle> .";
					}
				}
				$triples[] = "<" . $uri . "> <http://purl.org/void/provenance/ns/resultingDataset> <" . $remote_path . "/" . $localfile . "> .";
				$triples[] = "<" . $uri . "> <http://purl.org/void/provenance/ns/sourceDataset> <" . str_replace("#provenance", "", $base_uri) . "> .";
				$triples[] = "<" . $uri . "> <http://www.w3.org/2006/time#hasBeginning> \"" . $datestring . "\"^^<http://www.w3.org/2001/XMLSchema#dateTime> .";
				$triples[] = "<" . $uri . "> <http://www.w3.org/2006/time#hasEnd> \"" . $datenow . "\"^^<http://www.w3.org/2001/XMLSchema#dateTime> .";
			}
			$metadata = $this->createMetadata($remote_path . "/" . $localfile);
			$triples = array_unique(array_merge($triples, $metadata));
		}
		
		return($triples);
	}

	// Function to add meta-data to a dump file
	private function createMetadata($uri)
	{
		// Read the configuration file
		$cfg_obj = $this->config;
		$cfg_properties = $cfg_obj['properties'];

		$ttl = array();
		if(array_key_exists('title', $cfg_properties))
		{
			$ttl[] = "<" . $uri . "> <http://purl.org/dc/terms/title> \"" . str_replace("\"", "\\\"", $cfg_properties['title']) . "\" .";
		}
		if(array_key_exists('description', $cfg_properties))
		{
			$ttl[] = "<" . $uri . "> <http://purl.org/dc/terms/description> \"" . str_replace("\"", "\\\"", $cfg_properties['description']) . "\" .";
		}
		if(array_key_exists('stars', $cfg_properties))
		{
			$ttl[] = "<" . $uri . "> <http://purl.org/dc/terms/conformsTo> <http://purl.org/openorg/opendata-" . $cfg_properties['stars'] . "-star> .";
		}
		if(array_key_exists('license', $cfg_properties))
		{
			$licenses = $cfg_properties['license'];
			if(is_array($licenses))
			{
				foreach($licenses as $license)
				{
					$ttl[] = "<" . $uri . "> <http://purl.org/dc/terms/license> <" . $license . "> .";
				}
			}
		}
		if(array_key_exists('publisheruri', $cfg_properties))
		{
			$ttl[] = "<" . $uri . "> <http://purl.org/dc/terms/publisher> <" . $cfg_properties['publisheruri'] . "> .";
			if(array_key_exists('publishername', $cfg_properties))
			{
				$ttl[] = "<" . $cfg_properties['publisheruri'] . "> <http://www.w3.org/2000/01/rdf-schema#label> \"" . str_replace("\"", "\\\"", $cfg_properties['publishername']) . "\" .";
			}

		}
		if(array_key_exists('corrections', $cfg_properties))
		{
			if(preg_match("/.*@.*/", $cfg_properties['corrections']) > 0)
			{
				$ttl[] = "<" . $uri . "> <http://purl.org/openorg/corrections> <mailto:" . $cfg_properties['corrections'] . "> .";
			}
			else
			{
				$ttl[] = "<" . $uri . "> <http://purl.org/openorg/corrections> <" . $cfg_properties['corrections'] . "> .";
			}
		}
		if(array_key_exists('endpoint', $cfg_properties))
		{
			$endpoints = $cfg_properties['endpoint'];
			if(is_array($endpoints))
			{
				foreach($endpoints as $endpoint)
				{
					$ttl[] = "<" . $uri . "> <http://rdfs.org/ns/void#sparqlEndpoint> <" . $endpoint . "> .";
				}
			}
		}
		if(array_key_exists('authority', $cfg_properties))
		{
			if($cfg_properties['authority'])
			{
				$ttl[] = "<" . $uri . "> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://purl.org/openorg/AuthoritativeDataset> .";
			}
			else
			{
				$ttl[] = "<" . $uri . "> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://purl.org/openorg/NonAuthoritativeDataset> .";
			}
		}
		
		return($ttl);
	}		

	
	public function name()
	{
		return($this->dataset);
	}

	public function count()
	{
		return($this->triples_count);
	}

	public function triples()
	{
		$triples = explode("\n", implode("", file($this->triples_file)));
		return($triples);
	}
	
	public function setting($settingName)
	{
		$s = $this->global_settings;
		if(array_key_exists($settingName, $s))
		{
			return($s[$settingName]);
		}
		else
		{
			return("");
		}
	}
	
	public function __construct($dataset, $quiet = false, $force = false, $settings_path = "")
	{

		$this->creation_time = time();

		// Create settings array

		// The settings path defaults to the 'settings' directory which should be
		// a sibling of the 'bin' directory in which the script is currently
		// running. If this isn't good for the current set-up, use the
		// environment variable HEDGEHOG_CONFIG to manually override.
		
		if(is_dir($settings_path))
		{
			$settings_dir = $settings_path;
		}
		else
		{
			@$settings_dir = $_SERVER['HEDGEHOG_CONFIG'];

			if(!(is_dir($settings_dir)))
			{
				if(array_key_exists("_", $_SERVER))
				{
					$parse = explode("/", $_SERVER['_']);
					$c = count($parse);
					@$parse[$c - 1] = "";
					@$parse[$c - 2] = "";
					$settings_dir = "/" . trim(implode("/", $parse), "/") . "/settings";
				} else {
					$settings_dir = "";
				}
			}
		}
		
		// Handle settings
		$this->quiet = $quiet;
		$this->force = $force;
		$this->dataset = $dataset;
		$this->triples_count = 0;
		$this->createSettings($settings_dir);
		$this->dumpfiles = array();
		$errors = $this->checkSettings();

		// Create temporary directories and files
		$uid = getmypid();
		@$tmp_dir = $this->global_settings['tmp_dir'];
		$this->hopper_path = $tmp_dir . "/" . $dataset . ".new." . $uid;
		$this->triples_file = $tmp_dir . "/" . $dataset . "-full.nt." . $uid;
		// Remove triples file if it already exists
		if(file_exists($this->triples_file))
		{
			unlink($this->triples_file);
		}
		// Prepare Working directory  (hopper)
		if(is_dir($this->hopper_path)) 
		{
			deltree($this->hopper_path);
		}
		mkdir($this->hopper_path, 0755, true);
		
		if(!(is_dir($this->hopper_path)))
		{
			$errors .= "Cannot create temporary path " . $this->hopper_path . "\n";
		}
		
		if(!$quiet)
		{
			print($errors);
		}
		$this->errors = $errors;
		if(strlen($errors) == 0)
		{
			$this->status = 0;
		}
		else
		{
			$this->status = 1;
		}
	}
	
	public function __destruct()
	{
		if(file_exists($this->triples_file))
		{
			unlink($this->triples_file);
		}
		if(is_dir($this->hopper_path))
		{
			deltree($this->hopper_path);
		}
	}
}

// Command line handling functions

function getDatasets()
{
	global $argv;

	$datasets = array();
	for($i = 1; $i < (count($argv)); $i++)
	{
		if (strcmp(substr($argv[$i], 0, 1), "-") != 0)
		{
			$datasets[] = trim($argv[$i], "/");
		}
	}
	
	return($datasets);
}

function createSwitches()
{
	global $argv;

	$switches = array();

	// Process command line arguments
	$datasets = array();
	$switches = array();
	for($i = 1; $i < (count($argv)); $i++)
	{
		if (strcmp(substr($argv[$i], 0, 1), "-") == 0)
		{
			$k = $argv[$i];
			$switches[$k] = '';
		}
	}
	
	// Set variable $quiet if the user requests it.
	if((array_key_exists("--quiet", $switches)) | (array_key_exists("-quiet", $switches)) | (array_key_exists("-q", $switches)))
	{
		$switches['quiet'] = true;
	}
	else
	{
		$switches['quiet'] = false;
	}
	
	// Set variable $force_import if the user requests it.
	if(array_key_exists("--force", $switches))
	{
		$switches['force_import'] = true;
	}
	else
	{
		$switches['force_import'] = false;
	}
	
	// Set variable $test_only if the user requests it.
	if(array_key_exists("--test", $switches))
	{
		$switches['test_only'] = true;
	}
	else
	{
		$switches['test_only'] = false;
	}
	
	// Set variable $skip_import if the user requests it.
	if(array_key_exists("--noimport", $switches))
	{
		$switches['skip_import'] = true;
	}
	else
	{
		$switches['skip_import'] = false;
	}

	// Display help if the user requests it.
	if((array_key_exists("--help", $switches)) | (array_key_exists("-help", $switches)) | (array_key_exists("-h", $switches)) | (array_key_exists("-?", $switches)))
	{
		$switches['help'] = true;
	}
	else 
	{
		$switches['help'] = false;
	}

	return($switches);
}

// A function to handle external processes better than shell_exec.

function externalScript($command_line)
{
	$descriptorspec = array(
		0 => array("pipe", "r"),  // stdin
		1 => array("pipe", "w"),  // stdout
		2 => array("pipe", "w"),  // stderr
	);

	$process = proc_open($command_line, $descriptorspec, $pipes);
	$stdout = stream_get_contents($pipes[1]);
	fclose($pipes[1]);
	$stderr = stream_get_contents($pipes[2]);
	fclose($pipes[2]);
	$ret = proc_close($process);

	$r = array();
	$r['code'] = $ret;
	$r['stdout'] = $stdout;
	$r['stderr'] = $stderr;

	return($r);
}

// Define a few file-related functions so we don't have to keep calling the shell.

function deltree($dir) // Delete a non-empty directory
{
	if(is_dir($dir))
	{
		if ($handle = opendir($dir))
		{
			while (false !== ($entry = readdir($handle)))
			{
				if(!(is_dir($entry)))
				{
					unlink($dir . "/" . $entry);
				}
				else
				{
					if((!(strcmp($entry, ".."))) & (!(strcmp($entry, "."))))
					{
						deltree($dir . "/" . $entry);
					}
				}
			}
			closedir($handle);
		}
	}
	rmdir($dir);
}

function dupdir($src, $dst) // Duplicate a directory (non-recursive)
{
	if(!(is_dir($dst)))
	{
		mkdir($dst, 0755, true);
	}
	if(is_dir($src))
	{
		if ($handle = opendir($src))
		{
			while (false !== ($entry = readdir($handle)))
			{
				if(!(is_dir($src . "/" . $entry)))
				{
					$file_perms = fileperms($src . "/" . $entry);
					copy($src . "/" . $entry, $dst . "/" . $entry);
					chmod($dst . "/" . $entry, $file_perms);
				}
			}
			closedir($handle);
		}
	}
}

function wget($url, $file)
{

	if(function_exists("curl_init"))
	{
		$ch = curl_init();
		$timeout = 5;
		curl_setopt($ch, CURLOPT_URL, $url);
		curl_setopt($ch, CURLOPT_RETURNTRANSFER, 1);
		curl_setopt($ch, CURLOPT_CONNECTTIMEOUT, $timeout);
		$fp = fopen($file, "w");
		fwrite($fp, curl_exec($ch));
		fclose($fp);
		curl_close($ch);
	}
	else
	{
		// Included for portability, some PHP installs aren't compiled with cURL
		$data = implode("", file($url));
		$fp = fopen($file, "w");
		fwrite($fp, $data);
		fclose($fp);
	}
}


// 4Store Import
function import_4store($url, $graph, $triples)
{
	$max_triples = 10000;
	
	$r = array();
	if(count($triples) > $max_triples)
	{
		$chunked = array();
		$chunk = array();
		$i = 0;
		foreach($triples as $triple)
		{
			$chunk[] = $triple;
			$i++;
			if($i >= $max_triples)
			{
				$chunked[] = $chunk;
				$chunk = array();
				$i = 0;
			}
		}
		$chunked[] = $chunk;
		$i = 0;
		foreach($chunked as $chunk)
		{
			$data = implode("\n", $chunk);
			if($i == 0)
			{
				$ch = curl_init();
				curl_setopt($ch, CURLOPT_URL, $url . $graph);
				curl_setopt($ch, CURLOPT_HTTPHEADER, array('Content-Type: application/x-turtle','Content-Length: ' . strlen($data)));
				curl_setopt($ch, CURLOPT_VERBOSE, 0);
				curl_setopt($ch, CURLOPT_RETURNTRANSFER, true);
				curl_setopt($ch, CURLOPT_CUSTOMREQUEST, "PUT"); 
				curl_setopt($ch, CURLOPT_POSTFIELDS, $data);
				curl_setopt($ch, CURLOPT_SSL_VERIFYPEER, 0);
				$success_report = str_replace("\n", ", ", trim(curl_exec($ch)));
				if(strcmp(substr($success_report, 0, 3), "400") == 0)
				{
					print("\n\n");
					print($data);
					exit();
				}
				$r[] = $success_report;
				curl_close($ch);
			}
			else
			{
				$postdata = array('graph' => $graph, 'data' => $data, 'mime-type' => 'application/x-turtle');
				$ch = curl_init();
				curl_setopt($ch, CURLOPT_URL, $url);
				curl_setopt($ch, CURLOPT_HTTPHEADER, array('Content-Type: application/x-www-form-urlencoded'));
				curl_setopt($ch, CURLOPT_RETURNTRANSFER, true);
				curl_setopt($ch, CURLOPT_POST, true);
				curl_setopt($ch, CURLOPT_POSTFIELDS, http_build_query($postdata));
				$r[] = str_replace("\n", ", ", trim(curl_exec($ch)));
				curl_close($ch);
			}
			$i++;
		}
	}
	else
	{
		$data = implode("\n", $triples);
		$ch = curl_init();
		curl_setopt($ch, CURLOPT_URL, $url . $graph);
		curl_setopt($ch, CURLOPT_HTTPHEADER, array('Content-Type: application/x-turtle','Content-Length: ' . strlen($data)));
		curl_setopt($ch, CURLOPT_VERBOSE, 0);
		curl_setopt($ch, CURLOPT_RETURNTRANSFER, true);
		curl_setopt($ch, CURLOPT_CUSTOMREQUEST, "PUT"); 
		curl_setopt($ch, CURLOPT_POSTFIELDS, $data);
		curl_setopt($ch, CURLOPT_SSL_VERIFYPEER, 0);
		$r[] = str_replace("\n", ", ", trim(curl_exec($ch)));
		//$chapierr = curl_errno($ch);
		//$cherrmsg = curl_error($ch);
		curl_close($ch);
	}
	
	return(implode("\n                  ", $r));
}

// Function for displaying command line help.
function display_help($extended=0)
{
	print("publish_dataset\n");
	print("---------------\n");
	print("A tool for publishing datasets within the Hedgehog system.\n\n");
	print("Usage: publish_dataset (options) dataset [dataset [dataset [...]]]\n\n");
	if($extended == 1)
	{
		// Show extended help
		print("Options\n");
		print("  --help\tShow this help screen\n");
		print("  --quiet\tNo output (good for cron)\n");
		print("  --force\tImport even if nothing has changed\n");
		print("  --test\tTest mode, check files without importing\n");
		print("  --noimport\tPerform everything except the final import\n");
	} else {
		print("Use --help switch for more options.\n");
	}
	print("\n");
}

// ================== Main script start here =================================

$switches = createSwitches();
$datasets = getDatasets();

// Display help page if requested, or if parameters are incorrect.
if(($switches['help']) | (count($datasets) == 0))
{
	if($switches['help'])
	{
		display_help(1);
	} else {
		display_help();
	}
	exit();
}

foreach($datasets as $dataset)
{
	$ds = new HedgehogDataset($dataset, $switches['quiet'], $switches['force_import']);
	if($ds->status == 0)
	{
		$ds->prepare();
		
		if($ds->changedFiles() | $ds->force) // Only continue if files unchanged, or publish explicitly forced
		{
			// Publish the dataset
		
			$ds->requestRdfDump($ds->name() . ".rdf", "rdfxml");
			$ds->requestRdfDump($ds->name() . ".ttl", "turtle");
			$ds->publish();

			// Import to the triplestore
			$import_url = $ds->setting("import_url");
			$graph_uri = $ds->setting("xml_base") . "/dataset/" . $ds->name() . "/latest";
			if((strlen($import_url) > 0) & (strlen($graph_uri) > 0))
			{
				if(!$switches['quiet'])
				{
					print("     " . $graph_uri . "\n");
					print("     Importing... ");
				}
				$import_result = import_4store($import_url, $graph_uri, $ds->triples());
				if(!$switches['quiet'])
				{
					print($import_result . "\n");
				}
			}

			
		}
	}
	else
	{
		exit();
	}
}

?>